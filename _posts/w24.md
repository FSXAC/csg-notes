---
date: 2020-06-07
title: Week 0
---

**Edge application**: *edge computing* is the idea of moving the data-processors such as data-centres or servers closer to client (think of performing ML locally or using a nearby computer instead of uploading to the “cloud”). 

### Going Deeper with Embedded FPGA Platform for Convolutional Neural Network (2016)

> ❓ what is Fully-Connected (FC) layer and how does it differ from convolutional (CONV) layers? Why is that they say FC layers are memory-centric while CONV are computation-centric? What does it mean to be something-centric anyway?



### DNNBuilder (2018)

*DNNBuilder* is a automatic tool for converting DNNs into FPGA (RTL). 

Techniques for increasing throughput, reduce latency, and save FPGA footprint:

- High-quality RTL neural network components
- Fine-grained layer-based pipeline architecture
- Column-based cache scheme

Background: FPGAs are promising solutions for flexible hardware acceleration. But the problem is designs on FPGAs require tedious RTL programming and verification.

Main contributions of the paper:

1. End-to-end automation tool to deploy DNNs on FPGAs.
2. Flexible quantization scheme (recall quantization is taking the floating point valuies of weights and activations and quantize it into some arbitrarily discrete levels — thus reducing data necessary to represent it).
3. Fine-grained layer-based pipeline architecture and a column based cached scheme.
4. Autogen highly optimized RTL network components
5. Automatically management of resources allocation such as external memory access bandwidth, data reuse, computation resource availability, and network complexity.

### Other Learnings

*Stored program concept* is the idea that programs are “soft” and can be loaded/unloaded to and from memory so that we don’t have to store programs in hardware. 